{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from splitdata import split_data\n",
        "from normalize_ohlcv import normalize_ohlcv\n",
        "from deeplearningmodel import build_model\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Step 1: Load Data\n",
        "file_path = 'btc_with_normalized_indicators.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Split Data (Train/Test)\n",
        "train_set, test_set = split_data(data, train_ratio=0.8, sequence_length=100)\n",
        "\n",
        "# Step 3: Prepare Data for LSTM (Create X and y)\n",
        "# def prepare_lstm_data(data, sequence_length, predict_length):\n",
        "#     X, y = [], []\n",
        "#     for i in range(len(data) - sequence_length - predict_length + 1):\n",
        "#         X.append(data.iloc[i:i + sequence_length].values)  # Input sequences\n",
        "#         y.append(data.iloc[i + sequence_length:i + sequence_length + predict_length]['close'].values)  # Target sequences\n",
        "#     return X, y\n",
        "def prepare_lstm_data(data, sequence_length, predict_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length - predict_length + 1):\n",
        "        X.append(data[i:i + sequence_length])  \n",
        "        y.append(data[i + sequence_length:i + sequence_length + predict_length, -1])  \n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "sequence_length = 100\n",
        "predict_length = 50\n",
        "\n",
        "X_train, y_train = prepare_lstm_data(train_set, sequence_length, predict_length)\n",
        "X_test, y_test = prepare_lstm_data(test_set, sequence_length, predict_length)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "\n",
        "\n",
        "# Step 4: Build Model\n",
        "model = build_model(input_shape=(sequence_length, X_train.shape[2]))  # Adjust shape automatically\n",
        "\n",
        "# Step 5: Train Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 6: Evaluate Model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Step 7: Save Model\n",
        "model.save('bitcoin_prediction_model.h5')\n",
        "\n",
        "# Step 8: Optional - Make Predictions\n",
        "predictions = model.predict(X_test[:5])  # Predict the first 5 sequences in the test set\n",
        "print(\"Predictions for the first 5 sequences:\")\n",
        "print(predictions)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}